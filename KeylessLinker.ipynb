{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"145eKUBFNm9LSXxfZExGs7QP7noQLfj69","authorship_tag":"ABX9TyM+pzue7OPYK8a9mj7N1xfx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Clean slate (optional but helps avoid version pin conflicts)\n","!pip -q install --upgrade pip\n","\n","# Correct packages: faiss-CPU and scikit-learn (NOT 'sklearn')\n","!pip -q install pandas numpy scipy scikit-learn rapidfuzz jellyfish sentence-transformers faiss-cpu networkx\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xRd4iZiKZ-hM","executionInfo":{"status":"ok","timestamp":1755155602666,"user_tz":-180,"elapsed":10962,"user":{"displayName":"Mohamad Ghazy","userId":"11486589038347141524"}},"outputId":"88b2f7dc-e784-4bb1-bc38-61a058f2021c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.8 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m1.5/1.8 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":32,"metadata":{"id":"s1OrdHHMXqu6","executionInfo":{"status":"ok","timestamp":1755158199964,"user_tz":-180,"elapsed":214,"user":{"displayName":"Mohamad Ghazy","userId":"11486589038347141524"}}},"outputs":[],"source":["import pandas as pd, numpy as np, re, math, itertools, networkx as nx\n","from rapidfuzz import fuzz\n","import jellyfish\n","from sentence_transformers import SentenceTransformer\n","import faiss\n","from sklearn.mixture import GaussianMixture\n","\n","# === CONFIG ===\n","File   = \"/content/drive/MyDrive/Colab Notebooks/Projects_Merge.xlsx\"   # Oracle side\n","LEFT_CODE_COL  = \"Code\"\n","LEFT_NAME_COL  = \"Project Name \"\n","RIGHT_CODE_COL = \"Code\"\n","RIGHT_NAME_COL = \"Project\"\n","\n","# === LOAD ===\n","L = pd.read_excel(File, sheet_name='Oracle').fillna(\"\")\n","R = pd.read_excel(File, sheet_name='MSProject').fillna(\"\")\n","\n","# keep only needed cols\n","L = L[[LEFT_CODE_COL, LEFT_NAME_COL]].copy()\n","R = R[[RIGHT_CODE_COL, RIGHT_NAME_COL]].copy()\n","\n","L.rename(columns={LEFT_CODE_COL:\"code\", LEFT_NAME_COL:\"name\"}, inplace=True)\n","R.rename(columns={RIGHT_CODE_COL:\"code\", RIGHT_NAME_COL:\"name\"}, inplace=True)\n","\n","L[\"row_id\"] = np.arange(len(L))\n","R[\"row_id\"] = np.arange(len(R))\n"]},{"cell_type":"code","source":["# --- Step 2: Compact normalization (replace your previous Step 2) ---\n","import re, unicodedata\n","\n","def normalize_compact(s: str) -> str:\n","    if not isinstance(s, str):\n","        s = \"\" if s is None else str(s)\n","    # lowercase\n","    s = s.lower().strip()\n","    # remove accents/diacritics (NFKD)\n","    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n","    # keep only a–z and 0–9 (drop spaces, / * - ( ) , etc.)\n","    s = re.sub(r\"[^a-z0-9]\", \"\", s)\n","    return s\n","\n","def numbers_compact(s: str):\n","    # pull number groups BEFORE stripping if you prefer; here we extract after compact form\n","    return re.findall(r\"\\d+\", s or \"\")\n","\n","# apply to both dataframes\n","for df in (L, R):\n","    # compact canonical form\n","    df[\"name_clean\"] = df[\"name\"].map(normalize_compact)\n","    # character-level \"tokens\" so the DP alignment works at char granularity\n","    df[\"name_tokens\"] = df[\"name_clean\"].map(list)\n","\n"],"metadata":{"id":"b1UQkIAEchEX","executionInfo":{"status":"ok","timestamp":1755158227772,"user_tz":-180,"elapsed":21,"user":{"displayName":"Mohamad Ghazy","userId":"11486589038347141524"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["# small, fast model\n","model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n","\n","def embed(texts):\n","    # returns L2-normalized vectors\n","    X = model.encode(texts, batch_size=256, convert_to_numpy=True, normalize_embeddings=True)\n","    return X.astype(\"float32\")\n","\n","X_L = embed(L[\"name_clean\"].tolist())\n","X_R = embed(R[\"name_clean\"].tolist())\n","\n","# build FAISS index on R\n","d = X_R.shape[1]\n","index = faiss.IndexFlatIP(d)       # cosine since vectors normalized\n","index.add(X_R)\n","K = 50  # number of candidates per left record (tune 30–100)\n","\n","sims, idxs = index.search(X_L, K)  # sims in [-1..1]\n"],"metadata":{"id":"usO1wtabfnwd","executionInfo":{"status":"ok","timestamp":1755158511849,"user_tz":-180,"elapsed":27004,"user":{"displayName":"Mohamad Ghazy","userId":"11486589038347141524"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["def token_sim(a: str, b: str) -> float:\n","    # character-level similarity per token (0..1)\n","    return fuzz.QRatio(a, b)/100.0\n","\n","def affine_align_score(A, B, gap_open=-0.7, gap_ext=-0.15, sub_floor=0.0):\n","    # A, B are token lists; returns [0..1]\n","    # substitution score is token_sim; gaps use affine penalties\n","    n, m = len(A), len(B)\n","    if n == 0 and m == 0: return 1.0\n","    if n == 0 or m == 0:  return 0.0\n","\n","    MINF = -1e9\n","    M = np.full((n+1, m+1), MINF, dtype=float)  # match/mismatch\n","    X = np.full((n+1, m+1), MINF, dtype=float)  # gap in A\n","    Y = np.full((n+1, m+1), MINF, dtype=float)  # gap in B\n","\n","    M[0,0] = 0.0\n","    for i in range(1, n+1):\n","        X[i,0] = gap_open + (i-1)*gap_ext\n","    for j in range(1, m+1):\n","        Y[0,j] = gap_open + (j-1)*gap_ext\n","\n","    for i in range(1, n+1):\n","        for j in range(1, m+1):\n","            s = max(token_sim(A[i-1], B[j-1]), sub_floor)  # floor avoids punishing near-matches too hard\n","            M[i,j] = s + max(M[i-1,j-1], X[i-1,j-1], Y[i-1,j-1])\n","            X[i,j] = max(M[i-1,j] + gap_open, X[i-1,j] + gap_ext)\n","            Y[i,j] = max(M[i,j-1] + gap_open, Y[i,j-1] + gap_ext)\n","\n","    best = max(M[n,m], X[n,m], Y[n,m])\n","\n","    # normalize by an upper bound (length of longer sequence)\n","    max_len = max(n, m)\n","    # assume perfect match token_sim≈1 gives ~1 per step; cap to [0,1]\n","    return max(0.0, min(1.0, best / max_len))\n"],"metadata":{"id":"gnlBBjrIfxF8","executionInfo":{"status":"ok","timestamp":1755156782661,"user_tz":-180,"elapsed":123,"user":{"displayName":"Mohamad Ghazy","userId":"11486589038347141524"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def numeric_overlap(nums_a, nums_b):\n","    return 1.0 if set(nums_a) & set(nums_b) else 0.0\n","\n","def phonetic_agree(p_a, p_b):\n","    return 1.0 if p_a == p_b and p_a != \"\" else 0.0\n","\n","# weights (will auto-calibrate threshold later; you can tweak if needed)\n","W_EMB   = 0.47\n","W_ALIGN = 0.47\n","W_NUM   = 0.06\n","W_PHON  = 0\n","\n","pairs = []  # (L_row, R_row, score, components...)\n","for i in range(len(L)):\n","    cand_js = idxs[i]\n","    cand_sims = sims[i]\n","    A = L.at[i, \"name_tokens\"]\n","    for j_idx, emb_sim in zip(cand_js, cand_sims):\n","        j = int(j_idx)\n","        B = R.at[j, \"name_tokens\"]\n","        align = affine_align_score(A, B)\n","        # combined\n","        score = (W_EMB*max(0.0, emb_sim) + W_ALIGN*align + W_NUM*numsc + W_PHON*phons)\n","        pairs.append((i, j, float(score), float(emb_sim), float(align), float(numsc), float(phons)))\n","\n","pairs_df = pd.DataFrame(pairs, columns=[\"L_id\",\"R_id\",\"score\",\"emb\",\"align\",\"num\",\"phon\"])\n"],"metadata":{"id":"AIjYloCDfzZ1","executionInfo":{"status":"ok","timestamp":1755157019496,"user_tz":-180,"elapsed":132250,"user":{"displayName":"Mohamad Ghazy","userId":"11486589038347141524"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["gmm = GaussianMixture(n_components=2, random_state=0).fit(pairs_df[[\"score\"]])\n","means = gmm.means_.ravel()\n","order = np.argsort(means)\n","hi = means[order[1]]\n","lo = means[order[0]]\n","# binary search a cut where posteriors equal\n","def post_p(x):\n","    p = np.exp(gmm.score_samples(np.array(x).reshape(-1,1)))\n","    return p\n","# simple numeric intersection (coarse)\n","grid = np.linspace(pairs_df[\"score\"].min(), pairs_df[\"score\"].max(), 200)\n","probs = gmm.predict_proba(grid.reshape(-1,1))\n","thr = float(grid[np.argmin(np.abs(probs[:,order[1]] - probs[:,order[0]]))])\n","thr = max(0.70, min(0.98, thr))  # clamp to sane range\n","thr"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LwZeWNuSgzCm","executionInfo":{"status":"ok","timestamp":1755157070694,"user_tz":-180,"elapsed":1377,"user":{"displayName":"Mohamad Ghazy","userId":"11486589038347141524"}},"outputId":"dd30d1eb-e1b5-4356-df71-87ea65517822"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but GaussianMixture was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["0.7"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["# keep only edges above threshold\n","edges = pairs_df[pairs_df[\"score\"] >= thr]\n","\n","# Build graph for max weight matching\n","G = nx.Graph()\n","for _, r in edges.iterrows():\n","    G.add_edge((\"L\", int(r[\"L_id\"])), (\"R\", int(r[\"R_id\"])), weight=float(r[\"score\"]))\n","\n","matching = nx.algorithms.matching.max_weight_matching(G, maxcardinality=True)\n","\n","# Convert to DataFrame\n","match_rows = []\n","for a,b in matching:\n","    if a[0]==\"L\":\n","        i, j = a[1], b[1]\n","    else:\n","        i, j = b[1], a[1]\n","    row = edges[(edges[\"L_id\"]==i) & (edges[\"R_id\"]==j)].sort_values(\"score\", ascending=False).iloc[0]\n","    match_rows.append(row)\n","\n","match_df = pd.DataFrame(match_rows).sort_values(\"score\", ascending=False).reset_index(drop=True)\n","\n","# Unmatched left/right\n","matched_L = set(match_df[\"L_id\"])\n","matched_R = set(match_df[\"R_id\"])\n","unmatched_L = [i for i in range(len(L)) if i not in matched_L]\n","unmatched_R = [j for j in range(len(R)) if j not in matched_R]\n","\n","len(match_df), len(unmatched_L), len(unmatched_R), float(thr)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eOdboDuwg0iw","executionInfo":{"status":"ok","timestamp":1755157183910,"user_tz":-180,"elapsed":4362,"user":{"displayName":"Mohamad Ghazy","userId":"11486589038347141524"}},"outputId":"d11ec784-58e0-4207-ed2f-9130ec8832dd"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(587, 1182, 1242, 0.7)"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["# Crosswalk with surrogate IDs\n","match_df[\"project_id\"] = np.arange(1, len(match_df)+1)\n","\n","# Assign new project_ids for unmatched as well\n","next_id = len(match_df) + 1\n","unmatchedL_df = pd.DataFrame({\"L_id\": unmatched_L, \"R_id\": [np.nan]*len(unmatched_L),\n","                              \"score\": [np.nan]*len(unmatched_L), \"project_id\": range(next_id, next_id+len(unmatched_L))})\n","next_id += len(unmatched_L)\n","unmatchedR_df = pd.DataFrame({\"L_id\": [np.nan]*len(unmatched_R), \"R_id\": unmatched_R,\n","                              \"score\": [np.nan]*len(unmatched_R), \"project_id\": range(next_id, next_id+len(unmatched_R))})\n","\n","crosswalk = pd.concat([match_df[[\"L_id\",\"R_id\",\"score\",\"project_id\"]], unmatchedL_df, unmatchedR_df], ignore_index=True)\n","\n","# Join codes/names back\n","cw = crosswalk.merge(L[[\"row_id\",\"code\",\"name\"]], left_on=\"L_id\", right_on=\"row_id\", how=\"left\", suffixes=(\"\",\"_L\"))\n","cw = cw.merge(R[[\"row_id\",\"code\",\"name\"]], left_on=\"R_id\", right_on=\"row_id\", how=\"left\", suffixes=(\"\",\"_R\"))\n","\n","cw.rename(columns={\"code\":\"oracle_code\",\"name\":\"oracle_name\",\"code_R\":\"excel_code\",\"name_R\":\"excel_name\"}, inplace=True)\n","cw[\"match_method\"] = np.where(cw[\"score\"].notna(), \"auto_alignment\", \"unmatched\")\n","cw[\"run_id\"] = pd.Timestamp.utcnow().isoformat()\n","for col in [\"oracle_name\", \"excel_name\"]:\n","    if col in cw.columns:\n","        cw[col] = cw[col].fillna(\"\").astype(str)\n","\n","def canonical_name(row):\n","    a = row.get(\"oracle_name\", \"\")\n","    b = row.get(\"excel_name\", \"\")\n","    # prefer non-empty; if both non-empty choose the longer\n","    if a and not b:\n","        return a\n","    if b and not a:\n","        return b\n","    return a if len(a) >= len(b) else b\n","\n","cw[\"canonical_name\"] = cw.apply(canonical_name, axis=1)\n","\n","# Save results\n","CROSSWALK_CSV = \"/content/crosswalk.csv\"\n","MASTER_CSV    = \"/content/master_projects.csv\"\n","\n","cw[[\"project_id\",\"oracle_code\",\"excel_code\",\"oracle_name\",\"excel_name\",\"canonical_name\",\"score\",\"match_method\",\"run_id\"]].to_csv(CROSSWALK_CSV, index=False)\n","\n","master = cw.groupby(\"project_id\").agg({\n","    \"canonical_name\":\"first\",\n","    \"oracle_code\":lambda s: \";\".join(sorted(set([x for x in s if isinstance(x,str)]))),\n","    \"excel_code\": lambda s: \";\".join(sorted(set([x for x in s if isinstance(x,str)])))\n","}).reset_index()\n","\n","master.to_csv(MASTER_CSV, index=False)\n","\n","CROSSWALK_CSV, MASTER_CSV\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dWs4NXU9hStB","executionInfo":{"status":"ok","timestamp":1755157420735,"user_tz":-180,"elapsed":294,"user":{"displayName":"Mohamad Ghazy","userId":"11486589038347141524"}},"outputId":"fe952a32-9312-4ae7-e598-381c88ad0c6e"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('/content/crosswalk.csv', '/content/master_projects.csv')"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":[],"metadata":{"id":"btzs_G4ohWMS"},"execution_count":null,"outputs":[]}]}